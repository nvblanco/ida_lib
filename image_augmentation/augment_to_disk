from skimage import io
from operations.utils import save_im, element_to_dict_csv_format
import torchvision
from tqdm import tqdm, trange
import os
import csv
import pandas as pd

from torch.utils.data import Dataset
from core.pipeline import *


class AgmentToDisk(object):
    def __init__(self,
                 dataset: Dataset,
                 samples_per_item=2,
                 operations=None,
                 interpolation='bilinear',
                 padding_mode='zeros',
                 resize=None,
                 output_extension = '.jpg',
                 output_csv_path='anotations.csv',
                 output_path = './augmented'
                 ):
        self.dataset = dataset
        self.samples_per_item = samples_per_item
        self.output_extension = output_extension
        self.output_path = output_path
        self.output_csv_path = output_csv_path
        self.output_csv = []
        self.types2d = None
        self.other_types = None
        self.pipeline = pipeline(interpolation=interpolation,
                                 padding_mode=padding_mode,
                                 resize=resize,
                                 pipeline_operations=operations)

        if not os.path.exists(output_path):
            os.makedirs(output_path)

    def save_item(self, item, index, output_path, types_2d, other_types):
        item['id'] = item['id'] + '_' + str(index)
        for type in types_2d:
            if 'image' in type:
                name = output_path + '/' + item['id']
            else:
                name = output_path + item['id'] + '-' + type + '_' + str(index)
            save_im(tensor=item[type], title=(name + self.output_extension))
        self.output_csv.append(dict((label, item[label]) for label in (other_types)))

    def final_save(self,):
        csv_columns = self.output_csv[0].keys()
        try:
            with open(self.output_csv_path, 'w') as csvfile:
                writer = csv.DictWriter(csvfile, fieldnames=csv_columns)
                writer.writeheader()
                for data in self.output_csv:
                    writer.writerow(data)
        except IOError:
            print("I/O error")

    def __call__(self, *args, **kwargs):
        pbar = trange(len(self.dataset))
        for i in pbar:
            pbar.set_description("Processing image " + str(i) + " of the input dataset ")
            item = [self.dataset[i] for _ in range(self.samples_per_item)]
            augmented = self.pipeline(item)
            self.types2d, self.other_types = self.pipeline.get_data_types()
            if self.types2d is None:
                self.types2d, self.other_types = self.pipeline.get_data_types()
            for index, item in enumerate(augmented):
                self.save_item(item, index, types_2d=self.types2d, other_types=self.other_types, output_path=self.output_path)
        self.final_save()
        total_images = len(self.dataset) * self.samples_per_item
        print("Generated " + str(total_images) + " new images from the original dataset.")


#samples_per_item = 5


class FaceLandmarksDataset(Dataset):
    """Face Landmarks dataset."""

    def __init__(self, csv_file, root_dir, transform=None):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.landmarks_frame = pd.read_csv(csv_file)
        self.root_dir = root_dir
        self.transform = transform

    def __len__(self):
        return len(self.landmarks_frame)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()

        img_name = os.path.join(self.root_dir,
                                self.landmarks_frame.iloc[idx, 0])
        id = (self.landmarks_frame.iloc[idx, 0]).split('.')[0]
        image = io.imread(img_name)
        landmarks = self.landmarks_frame.iloc[idx, 1:]
        landmarks = np.array([landmarks])
        landmarks = landmarks.astype('float').reshape(-1, 2)
        sample = {'id': id, 'image': image, 'landmarks': landmarks}

        return sample


face_dataset = FaceLandmarksDataset(csv_file='../faces/face_landmarks.csv',
                                    root_dir='../faces/')

augmentor = AgmentToDisk(dataset = face_dataset,
                 samples_per_item=50,
                 operations=(randomScalePipeline(probability=0.6, scale_range=(0.8, 1.2), center_desviation=20),
                             hflipPipeline(probability=0.5),
                             randomContrastPipeline(probability=0.5, contrast_range=(1,1.5))),
                 interpolation='nearest',
                 padding_mode='zeros',
                 resize=None,
                 output_extension = '.jpg',
                 output_csv_path='anotations.csv',
                 output_path = './augmented_custom')

augmentor()

'''output_csv = []
output_path = './augmented'
extension = '.jpg'


def save_item(item, index, output_path, types_2d, other_types):
    item['id'] = item['id'] + '_' + str(index)
    labels_dict = {}
    for type in types_2d:
        if 'image' in type:
            name = output_path + '/' + item['id']
        else:
            name = output_path + item['id'] + '-' + type + '_' + str(index)
        save_im(tensor=item[type], title=(name + extension))
    for label in other_types:
        labels_dict.update(element_to_dict_csv_format(item[label], label))
    output_csv.append(labels_dict)


def final_save(output_csv_path='anotations.csv'):
    csv_columns = output_csv[0].keys()
    try:
        with open(output_csv_path, 'w') as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=csv_columns)
            writer.writeheader()
            for data in output_csv:
                writer.writerow(data)
    except IOError:
        print("I/O error")

samples_per_item = 5
face_dataset = FaceLandmarksDataset(csv_file='../faces/face_landmarks.csv',
                                    root_dir='../faces/')

pip = pipeline(interpolation='nearest', pipeline_operations=(
    translatePipeline(probability=0.5, translation=(3, 1)),
    vflipPipeline(probability=0.5),
    hflipPipeline(probability=0.5),
    contrastPipeline(probability=0.5, contrast_factor=1),
    randomBrightnessPipeline(probability=0.5, brightness_range=(1, 1.2)))
               )

if not os.path.exists(output_path):
    os.makedirs(output_path)
pbar = trange(len(face_dataset))
for i in pbar:
    pbar.set_description("Processing image " + str(i) + " of the input dataset ")
    item = [face_dataset[i] for _ in range(samples_per_item)]
    augmented = pip(item)
    types2d, other_types = pip.get_data_types()
    for index, item in enumerate(augmented):
        save_item(item, index, types_2d=types2d, other_types=other_types, output_path=output_path)
final_save()
'''