import kornia
import torch
import abc
from abc import ABCMeta

from image_augmentation import visualization

data_types_2d = {"image", "mask", "heatmap"}
data_types_1d = {"keypoints"}

device = 'cuda'
one_torch = torch.ones(1).to(device)


def keypoints_to_homogeneus_functional(keypoints):
    if keypoints[0].dim() == 1 : keypoints  = [point.reshape(2,1) for point in keypoints]
    return tuple([torch.cat((point.float(), torch.ones(1,1)), axis = 0).to(device) for point in keypoints])

#converts the intermediate values ​​generated by the transformations to 0-1
def mask_change_to_01_functional(mask):
    for i in range(mask.shape[1]):
        for j in range(mask.shape[2]):
            if mask[0, i, j] < 0.5:
                mask[0, i, j] = 0
            else:
                mask[0, i, j] = 1



class transform(object):
    __metaclass__ = ABCMeta

    @abc.abstractmethod
    def __init__(self, data, visualize=False):
        self.visualize = visualize
        result_data = {}
        if visualize:
            self.original = data
        if isinstance(data, dict):
            self.types_2d = {}
            compose_data = torch.tensor([])
            for type in data.keys():
                if type in data_types_2d:
                    compose_data = torch.cat((compose_data, data[type]),
                                             0)  # concatenate data into one multichannel pytoch tensor
                    self.types_2d[type] = data[type].shape[0]
                else:
                    self.points = data[type]
            self.data2d = compose_data.to(device)
            #self.types2d= types_2d
            if self.points is not None: self.data1d = keypoints_to_homogeneus_functional(points)
            return result_data
        else:
            if data.dim() < 3:
                raise Exception("Single data must be al least 3 dims")
            else:
                self.data2d = data

    def postprocess_data(self):
        self.data2d = self.data2d .cpu()
        if self.types_2d is not None:
            data_output = {}
            data_split = torch.split(self.data2d,  list(self.types_2d.values()), dim=0)
            for index, type in enumerate(self.types_2d):
                data_output[type] = data_split[index]
            data_output['keypoints'] = [((dato.cpu())[:2, :]).reshape(2) for dato in self.data1d]
            #if data_output.keys().__contains__('mask'): data_output['mask'] = mask_change_to_01_functional(data_output['mask'])
        else:
            data_output = self.data2d
        if self.visualize:
            visualization.plot_image_tranformation(data_output, self.original)
        return data_output


class vflip_transformation(transform):
    def __init__(self, data, visualize=False):
        transform.__init__(self, data, visualize)

    def __call__(self, *args, **kwargs):
        self.data2d = kornia.vflip(self.data2d)
        if self.data1d is not None:
            heigth = self.data2d.shape[-2]
            for point in self.data1d:
                point[1] = heigth - point[1]
        return transform.postprocess_data(self)

class hflip_transformation(transform):
    def __init__(self, data, visualize=False):
        transform.__init__(self, data, visualize)

    def __call__(self, *args, **kwargs):
        self.data2d = kornia.hflip(self.data2d)
        if self.data1d is not None:
            width = self.data2d.shape[-1]
            for point in self.data1d:
                point[0] = width - point[0]
        return transform.postprocess_data(self)

class affine_transformation(transform):
    def __init__(self, data,matrix, visualize=False):
        transform.__init__(self, data, visualize)
        self.matrix = matrix.to(device)

    def __call__(self, *args, **kwargs):
        kornia.geometry.affine(self.data2d, self.matrix)
        if self.data1d is not None:
            self.data1d = [torch.matmul(self.matrix, point) for point in self.data1d]
        return transform.postprocess_data(self)

'''
import cv2
import numpy as np
img: np.ndarray = cv2.imread('../gato.jpg')
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

def vflip(data, visualize = False):
    op = vflip_class(data, visualize)
    return op()

keypoints = ([img.shape[0]//2, img.shape[1]//2], [img.shape[0]//2  + 105, img.shape[1]//2 - 50])

# convert to torch tensor
data: torch.tensor = kornia.image_to_tensor(img, keepdim=False)  # BxCxHxW
points = [torch.from_numpy(np.asarray(point)) for point in keypoints]

data = {'image':data, 'mask': data,  'keypoints': points}
#input data


center = torch.ones(1, 2)
center[...,0]=100
center[...,1]= 50

vflip(data, True)
'''